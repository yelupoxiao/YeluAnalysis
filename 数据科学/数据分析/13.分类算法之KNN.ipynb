{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 应用场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所谓'近朱者赤近墨者黑'.KNN 的英文叫 K-Nearest Neighbor,作为数据挖掘中最简单的一种算法,应用也非常广泛.套用当下最流行的话题,使用KNN算法可以帮你轻松实现垃圾分类."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原理概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN整个计算过程分为三步：  \n",
    "- 计算待分类物体与其他物体之间的距离\n",
    "- 统计距离最近的K个邻居\n",
    "- 对于K个最近的邻居，它们属于哪个分类最多，待分类物体就属于哪一类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K值的选取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上过程可以看出，KNN算法中K值的选取是关键步骤。  \n",
    "若K值比较小，容易产生误差和过拟合；若K值比较大，会产生欠拟合，很多时候无法实现真正地分类。  \n",
    "实际工作中，K值是实践出真知的结果，并不是事先而定的。在工程上我们一般采用交叉验证的方式选取K值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 距离计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选取K值后，还有重要的计算就是关于距离的度量。两个样本点之间的距离代表了这两个样本之间的距离。距离越大，差异性越大；距离越小，差异性越小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "距离的计算方式主要有五种：**欧氏距离，曼哈顿距离,闵可夫斯基距离**,切比雪夫距离和余弦距离.其中前三种距离是KNN中最常用的."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 欧氏距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也叫欧几里得距离.在二维空间中,两点的欧式距离表达公式为:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d=\\sqrt{(x_1-y_1)^2+(x_2-y_2)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样可以求两点在n维空间中的距离："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d=\\sqrt{(x_1-y_1)^2+(x_2-y_2)^2+...+(x_n-y_n)^2}=\\sqrt{\\sum_{i=1}^{n}(x_i-y_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 曼哈顿距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "立体几何中用的比较多.如下图所示,绿线代表两点之间的欧式距离,红黄蓝线代表两点的曼哈顿距离.换句话曼哈顿距离等于两点在坐标系上的绝对轴距总和,用公式表达如下:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d=|x_1-y_1|+|x_2-y_2|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/KNN之欧氏距离与曼哈顿距离图示.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切比雪夫距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面提到的欧氏距离只能直线走，而曼哈顿距离只能沿着划定的格子边缘走。而切比雪夫中说的距离则是两者的结合体（即可直线走，也可沿着格子走）。二个点之间的距离定义是其各坐标数值差绝对值的最大值。此距离中，加入了优化的成分，通过最值来定义距离。数学表达公式为:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d=(|x_1-y_1|,|x_2-y_2|)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 闵可夫斯基距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "闵氏距离不是一种距离，而是一组距离的定义。对于n维空间中的两个点x(x1,x2,...xn)和y(y1,y2,...yn),闵可夫斯基距离表达公式:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d=p\\sqrt{\\sum{_{i=1}^{n}|x_i-y_i|^p}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中P代表空间的维数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 当p=1时，就是曼哈顿距离\n",
    "\n",
    "- 当p=2时，就是欧氏距离\n",
    "\n",
    "- 当p→∞时，就是切比雪夫距离\n",
    "\n",
    "根据变参数的不同，闵氏距离可以表示一类的距离。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 余弦距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "余弦距离，也称为余弦相似度，是用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小的度量。  \n",
    "向量，是多维空间中有方向的线段，如果两个向量的方向一致，即夹角接近零，那么这两个向量就相近。而要确定两个向量方向是否一致，这就要用到余弦定理计算向量的夹角。  \n",
    "余弦定理描述了三角形中任何一个夹角和三个边的关系。给定三角形的三条边，可以使用余弦定理求出三角形各个角的角度。假定三角形的三条边为a，b和c，对应的三个角为A，B和C，那么角A的余弦为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "cosA=\\frac{b_2+c_2-a_2}{2bc}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用余弦距离表示两个向量的相似度,通过余弦公式表达为:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "cosθ=\\frac{\\sum_{i=1}^{n}(A_i×B_i)}{\\sqrt{\\sum_{i=1}^{n}(A_i)^2}×\\sqrt{\\sum_{i=1}^{n}(B_i)^2}}=\\frac{A^T·B}{||A||×||B||}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||A||、||B||表示向量A、B的2范数.例如向量[1,2,3]的2范数为：$\\sqrt{1^2+2^2+3^2}=\\sqrt{14}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KD树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为KNN算法中涉及大量计算样本点之间的距离，为了减少计算次数、提升KNN搜索效率，人们提出了KD树（K-Dimenisonal）。KD树是对数据点在K维空间中划分的一种数据结构，KD树中的每个节点都K维数值点的二叉树，可以采用二叉树的增删改查操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN不仅可以做分类，还可以做回归。比如想对未知电影进行类型划分，这是一个分类问题，具体方法就是看下要分类的未知电影离它最近的K部电影大多数属于哪个分类，那这部电影就属于哪个分类。如果已知一部新电影是爱情片，想要知道它的打斗次数、接吻次数可能是多少，这就是一个回归问题。以上两个问题都可以依靠KNN算法解决。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在sklearn包中提供了KNN算法封装,当KNN做分类器的时候,需要引用:  \n",
    "> from sklearn.neighbors import KNeighborsCLassifier  \n",
    "\n",
    "当KNN做回归时,需要引用:  \n",
    "> from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN分类器参数介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造函数   \n",
    "KNeighborsClassifier(n_neighbors=5,weights='uniform',algorithm='auto',leaf_size=30)  \n",
    "- n_neighbors:即KNN中的K值,代表邻居的数量.K取值小会造成过拟合,取值大会造成欠拟合.一般默认值为5\n",
    "- weights:用来确定邻居的权重,有三种方式.一是weights=uniform,代表所有邻居的权重相同;weights=distance,代表权重是距离的倒数,即与距离成反比;自定义函数,可以自定义不同距离所对应的权重\n",
    "- algorithm:用来规定计算邻居的方法,有四种方式.一是algorithm=auto,根据数据的情况自动选择适合算法,为默认方式;二是algorithm=kd_tree,也叫作KD树,是多维空间的数据结构,方便对关键数据进行检索,需要注意的是KD树适用于维度少的情况,一般不超过20,否则效率反而会下降;三是algorithm=ball_tree,也叫作球树,和KD树一样是多维空间的数据结构,但适用于维度大的情况;四是algorithm=brute,也叫作暴力搜索,它和KD树不同的地方是在于采用的是线性扫描,而不是通过构造树结构进行快速检索,因此当训练集大的时候效率很低\n",
    "- leaf_size:代表构造KD树或球树时的叶子树,默认为30.通过调整叶子树会影响到树的构造和搜索速度."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 项目流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何对手写数字进行识别分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整体训练过程大体分为三个阶段:\n",
    "- 数据加载\n",
    "- 准备阶段,通过数据探索对数据有个初步了解,比如样本个数,图像什么样子,识别结果怎嘛用,可以通过可视化的方式呈现;通过数据清洗,如数据规范化让数据都在同一个数量级的维度\n",
    "- 分类阶段,通过训练得到分类器,然后用测试集进行准确率的计算."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码中,使用train_test_split做数据集的拆分,使用matplotlib.pyplot工具包显示图相关,使用accuracy_score进行分类器准确率的计算,使用preprocessing中的StandarScaler和MinMaxScaler做数据规范化."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "[[  0.   0.   5.  13.   9.   1.   0.   0.]\n",
      " [  0.   0.  13.  15.  10.  15.   5.   0.]\n",
      " [  0.   3.  15.   2.   0.  11.   8.   0.]\n",
      " [  0.   4.  12.   0.   0.   8.   8.   0.]\n",
      " [  0.   5.   8.   0.   0.   9.   8.   0.]\n",
      " [  0.   4.  11.   0.   1.  12.   7.   0.]\n",
      " [  0.   2.  14.   5.  10.  12.   0.   0.]\n",
      " [  0.   0.   6.  13.  10.   0.   0.   0.]]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加载数据\n",
    "digits = load_digits()\n",
    "data = digits.data\n",
    "# 数据探索\n",
    "print(data.shape)\n",
    "# 查看第一幅图像\n",
    "print(digits.images[0])\n",
    "# 第一幅图像代表的数字含义\n",
    "print(digits.target[0])\n",
    "# 将第一幅图像显示出来\n",
    "plt.gray()\n",
    "plt.imshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 准确率:0.9756\n"
     ]
    }
   ],
   "source": [
    "# 分割数据,将25%的数据作为测试集,其余作为训练集(你也可以指定其他比例的数据作为训练集)\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    data, digits.target, test_size=0.25, random_state=33)\n",
    "# 采用Z-Score规范化\n",
    "ss = preprocessing.StandardScaler()\n",
    "train_ss_x = ss.fit_transform(train_x)\n",
    "test_ss_x = ss.transform(test_x)\n",
    "# 创建KNN分类器\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(train_ss_x, train_y)\n",
    "predict_y = knn.predict(test_ss_x)\n",
    "print(u'KNN 准确率:{:.4f}'.format(accuracy_score(test_y, predict_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 准确率: 0.9867\n",
      " 多项式朴素贝叶斯准确率:0.8844\n",
      "CART 决策树准确率: 0.8422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\YY\\Anaconda\\envs\\Analysis\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 比较各种分类器的效果\n",
    "# 创建 SVM 分类器\n",
    "svm = SVC()\n",
    "svm.fit(train_ss_x, train_y)\n",
    "predict_y=svm.predict(test_ss_x)\n",
    "print('SVM 准确率: {:.4f}' .format(accuracy_score(test_y, predict_y)))\n",
    "# 采用 Min-Max 规范化\n",
    "mm = preprocessing.MinMaxScaler()\n",
    "train_mm_x = mm.fit_transform(train_x)\n",
    "test_mm_x = mm.transform(test_x)\n",
    "# 创建 Naive Bayes 分类器\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_mm_x, train_y) \n",
    "predict_y = mnb.predict(test_mm_x) \n",
    "print(\" 多项式朴素贝叶斯准确率:{:.4f}\" .format(accuracy_score(test_y, predict_y)))\n",
    "# 创建 CART 决策树分类器\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(train_mm_x, train_y) \n",
    "predict_y = dtc.predict(test_mm_x) \n",
    "print(\"CART 决策树准确率: {:.4f}\".format(accuracy_score(test_y, predict_y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在数据量不大的情况下,使用sklearn还是方便的.如果数据量很大,可采用深度学习+GPU运算的方式更适合,因为深度学习的特点就是需要大量并行的重复计算,GPU最擅长的就是大量的并行计算."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis]",
   "language": "python",
   "name": "conda-env-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 应用场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经典应用\"购物篮分析\";所谓的\"杀熟算法\"。关联规则挖掘生活中有很多场景，包括商品的捆绑销售，甚至在挑选演员决策上，也可以通过关联规则挖掘看出某个导演选择演员的倾向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关联规则挖掘可以从数据集中发现项(item)之间的关系.比如购物篮分析中可以从消费者交易记录发掘商品之间的关联关系,进而通过商品捆绑销售或相关推荐的方式来提升销售量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原理概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为便于理解关联规则挖掘算法的几个主要概念,下面给出一个超市购物的例子."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 订单编号  |购买的商品   |  \n",
    "|---|---|\n",
    "| 1  | 牛奶,面包,尿布  |  \n",
    "|  2 |  可乐,面包,尿布,啤酒 |  \n",
    "|  3 | 牛奶,尿布,啤酒,鸡蛋  |   \n",
    "|  4 | 面包,牛奶,尿布,啤酒  |  \n",
    "|  5 | 面包,牛奶,尿布,可乐  |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持度是个百分数,指某个商品组合出现的次数与总次数之间的比例.支持度越高,代表这个组合出现的频率越大."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'牛奶'出现4次,那么在5笔订单中'牛奶'的支持度就是4/5=0.8  \n",
    "'牛奶+面包'出现了3次,支持度就是3/5=0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 置信度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "置信度是个条件概念，就是说在A发生的情况下，B发生的概率是多少。   \n",
    "  \n",
    "置信度（牛奶→啤酒）=2/4=0.5，代表如果你购买了牛奶，有多大的概率会购买啤酒？  \n",
    "置信度（啤酒→牛奶）=2/3=0.67，代表如果你购买了啤酒，有多大概率购买牛奶？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提升度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做商品推荐重点考虑的是提升度，提升度代表的是“商品A的出现，对商品B出现的概率提升的”程度 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若是想衡量A出现的情况下，是否会对B出现的概率有所提升，表达公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提升度（A→B）=置信度（A→B）/支持度（B）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以提升度会有三种可能：\n",
    "- 提升度（A→B）>1：代表有提升；\n",
    "- 提升度（A→B）=1：代表没有提升，也没有下降；\n",
    "- 提升度（A→B）<1：代表有下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "英文叫做itemset，可以是单品，也可以是商品组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 频繁项集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "频繁项集是支持度大于等于最小支持度（Min Support）阈值项集，所以小于最小值支持度的项目就是非频繁项集，反之则是频繁项集。  \n",
    "**Apriori算法就是查找频繁项集的过程**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模拟Apriori算法流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把上例中商品用 ID 来代表，牛奶、面包、尿布、可乐、啤酒、鸡蛋的商品用 ID 来代表，牛奶、面包、尿布、可乐、啤酒、鸡蛋的商品ID 分别设置为 1-6，则数据表变为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 订单编号  |购买的商品   |  \n",
    "|---|---|\n",
    "| 1  | 1、2、3 |  \n",
    "|  2 |  4、2、3、5 |  \n",
    "|  3 | 1、3、5、6  |   \n",
    "|  4 | 2、1、3、5  |  \n",
    "|  5 | 2、1、3、4  |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设随机指定最小支持度是50%，也就是0.5，那么计算单个商品的支持度，即K=1项的支持度："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 商品项集  |支持度   |  \n",
    "|---|---|\n",
    "| 1  |4/5 |  \n",
    "|  2 |  4/5 |  \n",
    "|  3 | 5/5  |   \n",
    "|  4 | 2/5 |  \n",
    "|  5 | 3/5 |  \n",
    "|  6 | 1/5 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到商品4和6不符合最小支持度，不属于频繁项集，于是经过筛选商品的频繁项集变成："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 商品项集  |支持度   |  \n",
    "|---|---|\n",
    "| 1  |4/5 |  \n",
    "|  2 |  4/5 |  \n",
    "|  3 | 5/5  |     \n",
    "|  5 | 3/5 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在基础上，将商品两两组合，得到K=2项的支持度："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 商品项集  |支持度   |  \n",
    "|---|---|\n",
    "|1，2 |3/5 |  \n",
    "|  1，3 |  1/5 |  \n",
    "|  1，5| 2/5  |   \n",
    "|  2，3| 4/5 |  \n",
    "|  2，5 | 2/5 |  \n",
    "|  3，5| 3/5 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "筛掉小于最小支持度的商品组合，得到："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 商品项集  |支持度   |  \n",
    "|---|---|\n",
    "|1，2 |3/5 |     \n",
    "|  2，3| 4/5 |  \n",
    "|  3，5| 3/5 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将商品进行K=3组合，可以得到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 商品项集  |支持度   |  \n",
    "|---|---|\n",
    "|1，2，3 |3/5 |     \n",
    "|  1，3，5| 2/5 |  \n",
    "|  1，2，5| 1/5 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "筛选后得到："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 商品项集  |支持度   |  \n",
    "|---|---|\n",
    "|1，2，3 |3/5 |     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过以上过程，可以得到K=3项的频繁项集{1,2,3}，即{牛奶，面包，尿布}的组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结下Apriori的递归过程:  \n",
    "- K=1，计算K项集的支持度；\n",
    "- 筛选掉小于最小支持度的项集；\n",
    "- 如果项集为空，则对应K-1项集的结果为最终结果；\n",
    "- 如果项集不为空，则K=K+1，重复1-3步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FP-Growth算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori算法存在以下几个缺陷：\n",
    "- 可能产生大量的候选集，因为排列组合的方式把可能的项集都组合出来了；\n",
    "- 每次计算都要重新扫描数据集来计算每个项集的支持度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以Apriori会浪费很多计算空间和时间，于是有了Apriori的改进版FP-Growth算法，也是实际工作中常用的频繁项集挖掘方法：\n",
    "- 创建一颗FP树存储频繁项集；\n",
    "- 整个生成过程只遍历数据集2次，大大减少了计算量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建项头表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建项头表是为构建FP及为频繁项集挖掘提供索引，过程是先扫描一遍数据集，对于满足最小支持度的单个项(K=1)按照支持度从高到低进行排序，同时删除了不满足最小支持度的项。项头表包括了项目，支持度以及该项在FP树中的链表（初始为空）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 项  |支持度   |链表   |\n",
    "|---|---|---|\n",
    "|尿布 |5 |     \n",
    "| 牛奶| 4 |  \n",
    "| 面包| 4 |  \n",
    "|啤酒| 3 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造FP树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/关联分析Apriori之构造FP树.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FP的根节点是NULL节点，流程是再次扫描数据集，对于每一条数据，按照支持度从高到低的顺序进行创建节点（也就是第一步中项头表中的排序结果），节点如果存在就将计数count+1，如果不存在就进行创建。同时在创建的过程中更新项头表的链表。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过FP数挖掘频繁项集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过项头表来挖掘出每个频繁项集。具体的操作会用到一个概念**“条件模式基”**，它指的是以要挖掘的节点为叶子节点，自下而上求出FP树，然后将FP子树的祖先节点设置为叶子节点之和。既然求得目标对应的最大频繁项集."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里有些抽象,可以参考FP Tree算法图例资料进行辅助理解[FP Tree算法原理总结](https://www.cnblogs.com/zhengxingpeng/p/6679280.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FP Tree算法包括五步：\n",
    "\n",
    "- 扫描数据，得到所有频繁一项集的的计数。然后删除支持度低于阈值的项，将1项频繁集放入项头表，并按照支持度降序排列。\n",
    "- 扫描数据，将读到的原始数据剔除非频繁1项集，并按照支持度降序排列。\n",
    "- 读入排序后的数据集，插入FP树，插入时按照排序后的顺序，插入FP树中，排序靠前的节点是祖先节点，而靠后的是子孙节点。如果有共用的祖先，则对应的公用祖先节点计数加1。插入后，如果有新节点出现，则项头表对应的节点会通过节点链表链接上新节点。直到所有的数据都插入到FP树后，FP树的建立完成。\n",
    "- 从项头表的底部项依次向上找到项头表项对应的条件模式基。从条件模式基递归挖掘得到项头表项的频繁项集。\n",
    "- 如果不限制频繁项集的项数，则返回步骤4所有的频繁项集，否则只返回满足项数要求的频繁项集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现一种新理论的剔除,往往是先从最原始的概念出发,提出一种新的方法.原始概念最接近人们模拟的过程,但往往会存在空间时间复杂度过高的情况.后来人会对这个方法做改进型创新,重点是在空间和时间复杂度上进行降维,比如采用新型数据结构.可以看出树在存储和检索中是一个非常好用的数据结构."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn工具包没有Apriori，所以需要另外安装。可以通过[PyPI](https://pypi.org/)搜索工具包，也可以通过pip安装，输入命令:\n",
    "```\n",
    "pip install efficient-apriori\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "核心代码如下:\n",
    "```\n",
    "itemsets, rules = apriori(data, min_support,  min_confidence)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data是我们要提供的数据集,是一个list数组类型;   \n",
    "min_support参数为最小支持度,在efficient-apriori工具包中用0到1的数值表示百分比,比如0.5代表最小支持度为50%;  \n",
    "min_confidence是最小置信度,数值也代表百分比,比如1代表100%;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们用这个工具包,抛下上面讲到的超市购物的例子,具体实现代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficient_apriori import apriori\n",
    "# 设置数据集\n",
    "data = [('牛奶','面包','尿布'),\n",
    "           ('可乐','面包', '尿布', '啤酒'),\n",
    "           ('牛奶','尿布', '啤酒', '鸡蛋'),\n",
    "           ('面包', '牛奶', '尿布', '啤酒'),\n",
    "           ('面包', '牛奶', '尿布', '可乐')]\n",
    "# 挖掘频繁项集和频繁规则\n",
    "itemsets, rules = apriori(data, min_support=0.5,  min_confidence=1)\n",
    "print(itemsets)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 项目流程"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis]",
   "language": "python",
   "name": "conda-env-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
